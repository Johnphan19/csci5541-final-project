# Project Overview

 This project explores the effects of unlearning mathematical concepts in large language models (LLMs). Specifically, we analyze how removing knowledge of math affects reasoning, coding, and related tasks. Our approach includes reverse gradient ascent and label modification. We aim to quantify the extent of unlearning and its impact on adjacent knowledge domains, providing insight into the structure of learned representations in LLMs.
